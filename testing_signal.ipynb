{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     Path to your model 781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 10.1ms preprocess, 11.5ms inference, 48.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 136.5ms\n",
      "Speed: 5.5ms preprocess, 136.5ms inference, 178.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 124.6ms\n",
      "Speed: 4.0ms preprocess, 124.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 20.4ms\n",
      "Speed: 4.5ms preprocess, 20.4ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_4 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: GREEN\n",
      "\n",
      "Signal signal_4 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 88.5ms\n",
      "Speed: 7.0ms preprocess, 88.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: YELLOW\n",
      "\n",
      "\n",
      "0: 448x640 37 cars, 106.8ms\n",
      "Speed: 7.1ms preprocess, 106.8ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 18.4ms\n",
      "Speed: 4.6ms preprocess, 18.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_2 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: GREEN\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_2 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 34.0ms\n",
      "Speed: 7.9ms preprocess, 34.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 22.0ms\n",
      "Speed: 8.0ms preprocess, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 22.5ms\n",
      "Speed: 6.0ms preprocess, 22.5ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_3 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: GREEN\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_3 is YELLOW\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: YELLOW\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 85.0ms\n",
      "Speed: 8.0ms preprocess, 85.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 70.0ms\n",
      "Speed: 19.0ms preprocess, 70.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 45.0ms\n",
      "Speed: 7.0ms preprocess, 45.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 19.0ms\n",
      "Speed: 4.5ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_1 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: GREEN\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_1 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 86.9ms\n",
      "Speed: 8.0ms preprocess, 86.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 68.0ms\n",
      "Speed: 8.0ms preprocess, 68.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 27.0ms\n",
      "Speed: 5.0ms preprocess, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_4 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: GREEN\n",
      "\n",
      "Signal signal_4 is YELLOW\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: YELLOW\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 89.5ms\n",
      "Speed: 6.9ms preprocess, 89.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 85.5ms\n",
      "Speed: 5.0ms preprocess, 85.5ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 17.9ms\n",
      "Speed: 3.1ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_2 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: GREEN\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_2 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 92.1ms\n",
      "Speed: 7.0ms preprocess, 92.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 71.0ms\n",
      "Speed: 7.0ms preprocess, 71.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 37.0ms\n",
      "Speed: 6.5ms preprocess, 37.0ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 22.0ms\n",
      "Speed: 5.0ms preprocess, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_3 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: GREEN\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_3 is YELLOW\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: YELLOW\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 76.5ms\n",
      "Speed: 8.0ms preprocess, 76.5ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 67.0ms\n",
      "Speed: 7.0ms preprocess, 67.0ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 44.0ms\n",
      "Speed: 5.0ms preprocess, 44.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_1 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: GREEN\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_1 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 89.5ms\n",
      "Speed: 8.0ms preprocess, 89.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 83.0ms\n",
      "Speed: 6.0ms preprocess, 83.0ms inference, 5.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 22.0ms\n",
      "Speed: 4.0ms preprocess, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_4 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: GREEN\n",
      "\n",
      "Signal signal_4 is YELLOW\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: YELLOW\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 93.0ms\n",
      "Speed: 7.0ms preprocess, 93.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 69.0ms\n",
      "Speed: 13.0ms preprocess, 69.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 30.5ms\n",
      "Speed: 5.0ms preprocess, 30.5ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 23.0ms\n",
      "Speed: 4.0ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_2 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: GREEN\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_2 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 85.0ms\n",
      "Speed: 8.0ms preprocess, 85.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 69.0ms\n",
      "Speed: 9.0ms preprocess, 69.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 43.0ms\n",
      "Speed: 4.9ms preprocess, 43.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 17.9ms\n",
      "Speed: 4.1ms preprocess, 17.9ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_3 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: GREEN\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_3 is YELLOW\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: YELLOW\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 83.6ms\n",
      "Speed: 7.9ms preprocess, 83.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 76.1ms\n",
      "Speed: 11.1ms preprocess, 76.1ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 48.7ms\n",
      "Speed: 5.0ms preprocess, 48.7ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 18.9ms\n",
      "Speed: 4.1ms preprocess, 18.9ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_1 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: GREEN\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "Signal signal_1 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 82.1ms\n",
      "Speed: 9.0ms preprocess, 82.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 89.0ms\n",
      "Speed: 5.0ms preprocess, 89.0ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 20.0ms\n",
      "Speed: 3.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: YELLOW\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_4 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: GREEN\n",
      "\n",
      "Signal signal_4 is YELLOW\n",
      "\n",
      "0: 640x640 (no detections), 83.5ms\n",
      "Speed: 8.0ms preprocess, 83.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 71.1ms\n",
      "Speed: 7.0ms preprocess, 71.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 320x640 24 cars, 1 bus, 1 truck, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 49 cars, 2 buss, 1 truck, 18.0ms\n",
      "Speed: 4.5ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Signal signal_2 is GREEN\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: GREEN\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = r\"C:\\projects\\trafficmanagementsystem\\yolov8n.pt\"\n",
    "yolo_model = YOLO(model_path)\n",
    "\n",
    "image_feeds = {\n",
    "    'signal_1': r\"C:\\projects\\TMS\\Source_Codes\\b1dc7f6890ec09a8778714bea406e0d8.jpg\",\n",
    "    'signal_2': r\"C:\\projects\\TMS\\Source_Codes\\Heavy-rains-lash-Delhi-NCR-traffic-snarls-at-many-places-820x540.jpg\",\n",
    "    'signal_3': r\"C:\\projects\\TMS\\Source_Codes\\hero_TrafFicJam_Banner.jpg\",\n",
    "    'signal_4': r\"C:\\projects\\TMS\\Source_Codes\\shutterstock_110041646-scaled.jpg\"\n",
    "}\n",
    "\n",
    "traffic_lights = {\n",
    "    'signal_1': 'RED',\n",
    "    'signal_2': 'RED',\n",
    "    'signal_3': 'RED',\n",
    "    'signal_4': 'RED'\n",
    "}\n",
    "\n",
    "vehicle_counts = {\n",
    "    'signal_1': 0,\n",
    "    'signal_2': 0,\n",
    "    'signal_3': 0,\n",
    "    'signal_4': 0\n",
    "}\n",
    "\n",
    "recent_green_signals = deque(maxlen=3)\n",
    "\n",
    "def get_vehicle_count_from_feed(image_path):\n",
    "    frame = cv2.imread(image_path)\n",
    "    if frame is None:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    results = yolo_model(frame)\n",
    "    \n",
    "    \n",
    "    vehicle_count = sum(1 for result in results[0].boxes if result.cls in [1,2, 3, 5, 7])  # 2: car, 3: truck, 5: bus, 7: motorcycle\n",
    "    \n",
    "    \n",
    "    return vehicle_count\n",
    "\n",
    "def update_vehicle_counts():\n",
    "    for signal, image_path in image_feeds.items():\n",
    "        vehicle_counts[signal] = get_vehicle_count_from_feed(image_path)\n",
    "\n",
    "def open_signal(signal):\n",
    "    for s in traffic_lights.keys():\n",
    "        traffic_lights[s] = 'RED'\n",
    "    traffic_lights[signal] = 'GREEN'\n",
    "    recent_green_signals.append(signal)\n",
    "    print(f\"Signal {signal} is GREEN\")\n",
    "\n",
    "def change_signal_to_yellow(signal):\n",
    "    traffic_lights[signal] = 'YELLOW'\n",
    "    print(f\"Signal {signal} is YELLOW\")\n",
    "\n",
    "def display_status():\n",
    "    while True:\n",
    "        status = \"\\n\".join([f\"{signal}: {state}\" for signal, state in traffic_lights.items()])\n",
    "        print(f\"\\nTraffic Light Status:\\n{status}\\n\")\n",
    "        time.sleep(10)\n",
    "\n",
    "def manage_traffic():\n",
    "    while True:\n",
    "        update_vehicle_counts()\n",
    "        eligible_signals = [signal for signal in vehicle_counts if signal not in recent_green_signals]\n",
    "        sorted_signals = sorted(eligible_signals, key=lambda s: vehicle_counts[s], reverse=True)\n",
    "        \n",
    "        for signal in sorted_signals:\n",
    "            open_signal(signal)\n",
    "            time.sleep(10)\n",
    "            change_signal_to_yellow(signal)\n",
    "            time.sleep(5)\n",
    "            break\n",
    "\n",
    "def start_traffic_management():\n",
    "    traffic_management_thread = threading.Thread(target=manage_traffic)\n",
    "    traffic_management_thread.start()\n",
    "\n",
    "def start_display_status():\n",
    "    status_thread = threading.Thread(target=display_status)\n",
    "    status_thread.start()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_traffic_management()\n",
    "    start_display_status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = r\"C:\\projects\\trafficmanagementsystem\\yolov8n.pt\"\n",
    "yolo_model = YOLO(model_path)\n",
    "\n",
    "# Print all the class names\n",
    "class_names = yolo_model.names\n",
    "print(\"Classes in the YOLO model:\")\n",
    "for class_id, class_name in class_names.items():\n",
    "    print(f\"{class_id}: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 7.0ms preprocess, 13.0ms inference, 24.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 37 cars, 100.0ms\n",
      "Speed: 6.0ms preprocess, 100.0ms inference, 99.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (manage_traffic):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\haris\\anaconda3\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\haris\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\haris\\anaconda3\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\haris\\AppData\\Local\\Temp\\ipykernel_8440\\1061244971.py\", line 90, in manage_traffic\n",
      "  File \"C:\\Users\\haris\\AppData\\Local\\Temp\\ipykernel_8440\\1061244971.py\", line 69, in update_vehicle_counts\n",
      "  File \"C:\\Users\\haris\\AppData\\Local\\Temp\\ipykernel_8440\\1061244971.py\", line 57, in get_vehicle_count_from_feed\n",
      "  File \"c:\\Users\\haris\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py\", line 987, in __format__\n",
      "    return object.__format__(self, format_spec)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: unsupported format string passed to Tensor.__format__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n",
      "\n",
      "Traffic Light Status:\n",
      "signal_1: RED\n",
      "signal_2: RED\n",
      "signal_3: RED\n",
      "signal_4: RED\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "model_path = r\"C:\\projects\\trafficmanagementsystem\\yolov8n.pt\"\n",
    "yolo_model = YOLO(model_path)\n",
    "\n",
    "image_feeds = {\n",
    "    'signal_1': r\"C:\\projects\\TMS\\Source_Codes\\b1dc7f6890ec09a8778714bea406e0d8.jpg\",\n",
    "    'signal_2': r\"C:\\projects\\TMS\\Source_Codes\\Heavy-rains-lash-Delhi-NCR-traffic-snarls-at-many-places-820x540.jpg\",\n",
    "    'signal_3': r\"C:\\projects\\TMS\\Source_Codes\\hero_TrafFicJam_Banner.jpg\",\n",
    "    'signal_4': r\"C:\\projects\\TMS\\Source_Codes\\shutterstock_110041646-scaled.jpg\"\n",
    "}\n",
    "\n",
    "output_directory = r\"C:\\projects\\TMS\\Predicted_Images\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "traffic_lights = {\n",
    "    'signal_1': 'RED',\n",
    "    'signal_2': 'RED',\n",
    "    'signal_3': 'RED',\n",
    "    'signal_4': 'RED'\n",
    "}\n",
    "\n",
    "vehicle_counts = {\n",
    "    'signal_1': 0,\n",
    "    'signal_2': 0,\n",
    "    'signal_3': 0,\n",
    "    'signal_4': 0\n",
    "}\n",
    "\n",
    "recent_green_signals = deque(maxlen=3)\n",
    "\n",
    "def get_vehicle_count_from_feed(image_path, signal):\n",
    "    frame = cv2.imread(image_path)\n",
    "    if frame is None:\n",
    "        print(f\"Error reading image from {image_path}\")\n",
    "        return 0\n",
    "\n",
    "    results = yolo_model(frame)\n",
    "\n",
    "    # Define vehicle classes: 2: car, 3: truck, 5: bus, 7: motorcycle\n",
    "    vehicle_classes = [2, 3, 5, 7]\n",
    "    vehicle_count = sum(1 for result in results[0].boxes if int(result.cls) in vehicle_classes)\n",
    "    \n",
    "    # Draw bounding boxes on the frame\n",
    "    for result in results[0].boxes:\n",
    "        if int(result.cls) in vehicle_classes:\n",
    "            x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
    "            class_id = int(result.cls)\n",
    "            class_name = yolo_model.names[class_id]\n",
    "            confidence = result.conf\n",
    "            label = f\"{class_name} {confidence:.2f}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Save the annotated image\n",
    "    output_path = os.path.join(output_directory, f\"{signal}_predicted.jpg\")\n",
    "    cv2.imwrite(output_path, frame)\n",
    "\n",
    "    return vehicle_count\n",
    "\n",
    "def update_vehicle_counts():\n",
    "    for signal, image_path in image_feeds.items():\n",
    "        vehicle_counts[signal] = get_vehicle_count_from_feed(image_path, signal)\n",
    "\n",
    "def open_signal(signal):\n",
    "    for s in traffic_lights.keys():\n",
    "        traffic_lights[s] = 'RED'\n",
    "    traffic_lights[signal] = 'GREEN'\n",
    "    recent_green_signals.append(signal)\n",
    "    print(f\"Signal {signal} is GREEN\")\n",
    "\n",
    "def change_signal_to_yellow(signal):\n",
    "    traffic_lights[signal] = 'YELLOW'\n",
    "    print(f\"Signal {signal} is YELLOW\")\n",
    "\n",
    "def display_status():\n",
    "    while True:\n",
    "        status = \"\\n\".join([f\"{signal}: {state}\" for signal, state in traffic_lights.items()])\n",
    "        print(f\"\\nTraffic Light Status:\\n{status}\\n\")\n",
    "        time.sleep(10)\n",
    "\n",
    "def manage_traffic():\n",
    "    while True:\n",
    "        update_vehicle_counts()\n",
    "        eligible_signals = [signal for signal in vehicle_counts if signal not in recent_green_signals]\n",
    "        sorted_signals = sorted(eligible_signals, key=lambda s: vehicle_counts[s], reverse=True)\n",
    "        \n",
    "        for signal in sorted_signals:\n",
    "            open_signal(signal)\n",
    "            time.sleep(10)  # Green for 60 seconds\n",
    "            change_signal_to_yellow(signal)\n",
    "            time.sleep(5)  # Yellow for 5 seconds\n",
    "            break\n",
    "\n",
    "def start_traffic_management():\n",
    "    traffic_management_thread = threading.Thread(target=manage_traffic)\n",
    "    traffic_management_thread.start()\n",
    "\n",
    "def start_display_status():\n",
    "    status_thread = threading.Thread(target=display_status)\n",
    "    status_thread.start()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_traffic_management()\n",
    "    start_display_status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
